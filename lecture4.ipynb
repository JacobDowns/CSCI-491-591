{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFerxvtC62cUyFHe9cPujs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacobDowns/CSCI-491-591/blob/main/lecture4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MPI (Message Passing Interface)"
      ],
      "metadata": {
        "id": "4Ih39Vf5OBfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* MPI is a mechanism for inter-process communication.\n",
        "* Processes do not share memory. Instead they send messages to each other to communicate.\n",
        "* MPI is highly scalable, so it can operate on anything from **multiple cores** to **multiple nodes** in a cluster.\n",
        "* MPI is used widely in\n",
        "  * Weather models\n",
        "  * CFD models\n",
        "  * Finite Elements\n",
        "  * Numerical Linear Algebra\n",
        "  * Graph processing\n",
        "  * Astrophysics\n",
        "\n",
        "  among many other domains."
      ],
      "metadata": {
        "id": "owSbbIupOQY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mpi4py\n",
        "* Built on top of the C MPI standard\n",
        "*  Gives you almost full access to MPI, but it uses Python objects and NumPy arrays\n",
        "* Inter process communication can be achieved with\n",
        "  * Pickle based messaging (sending / receiving Python objects)\n",
        "  * Buffer based messaging (Writing / reading into NumPy arrays)\n",
        "* To execute a Python script that uses mpi4py you would use the command\n",
        "```\n",
        "mpiexec -n N python script.py\n",
        "```\n",
        "* This launches $N$ processes\n",
        "* Each process has a rank, which acts as its unique identifier $0, \\cdots, N-1$\n",
        "* Each process can access a communicator (usually called `MPI.COMM_WORLD`)\n",
        "* Processes can communicate point-to-point with other processes\n",
        "* They can also use collective operations like broadcast, scatter, gather, and reduce\n"
      ],
      "metadata": {
        "id": "JLJf1v2BYVWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minimal Program\n",
        "* Here's a minimal MPI program where wer're just installing dependencies, then looking at some of the basic syntax.\n"
      ],
      "metadata": {
        "id": "c30nsr6AbZy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y openmpi-bin openmpi-common libopenmpi-dev\n",
        "!pip install mpi4py"
      ],
      "metadata": {
        "id": "KARBOlsgbv7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mpi4py import MPI\n",
        "# The communicator\n",
        "comm = MPI.COMM_WORLD\n",
        "# Determines the rank of the current process\n",
        "rank = comm.Get_rank()\n",
        "# How many processes in total?\n",
        "size = comm.Get_size()\n",
        "\n",
        "data = rank\n",
        "total = comm.allreduce(data, op=MPI.SUM)\n",
        "print(f\"rank {rank} sees total = {total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN9UZPCObk0K",
        "outputId": "dc0206bd-6269-40a5-c01d-dfbf0b664be3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rank 0 sees total = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mental Model for MPI\n",
        "* As a mental model in MPI, every process runs the same code, but the processes rank determines exactly what role that process plays\n",
        "* Hence, there can be branching code for a specific process using syntax like\n",
        "```\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "jtOdDg6xa5NZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ3E7ym0yS56"
      },
      "outputs": [],
      "source": []
    }
  ]
}