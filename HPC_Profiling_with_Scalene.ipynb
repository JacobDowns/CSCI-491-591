{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48684b2",
   "metadata": {},
   "source": [
    "\n",
    "# HPC Profiling with **Scalene** (Python, NumPy/Numba, GPU, and MPI)\n",
    "\n",
    "**Goals**\n",
    "- Understand what Scalene measures (Python vs. native vs. GPU time, and memory).\n",
    "- Profile mixes of Python, NumPy/Numba, and GPU code paths.\n",
    "- Generate and read HTML reports.\n",
    "- Apply profiling to I/O-heavy workloads (optional Zarr demo).\n",
    "- Profile `mpi4py` programs rank-by-rank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cff35d",
   "metadata": {},
   "source": [
    "\n",
    "## What Scalene Measures (and why it matters)\n",
    "\n",
    "Scalene is a sampling profiler that attributes time to:\n",
    "- **Python time** (interpreter, GIL-bound)\n",
    "- **Native time** (NumPy/Numba/C-extensions)\n",
    "- **GPU time** (CuPy / Numba CUDA)\n",
    "- **Memory** (alloc/free) per line (where supported)\n",
    "\n",
    "This lets you decide whether to:\n",
    "- Vectorize / JIT (if Python time is high), or\n",
    "- Look at I/O / memory / algorithmic choices (if native/GPU time dominates).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb2aaf0",
   "metadata": {},
   "source": [
    "## Profiler Types: Sampling Profilers vs. Instrumenting Profilers\n",
    "\n",
    "Understanding how profilers collect their data is essential for interpreting results correctly — especially in HPC or hybrid Python + native code environments.\n",
    "\n",
    "---\n",
    "\n",
    "## Two Main Types of Profilers\n",
    "\n",
    "| Type | How It Works | Example Tools |\n",
    "|------|---------------|----------------|\n",
    "| **Sampling profiler** | Periodically interrupts a running program and records *where* it is (stack trace). | **Scalene**, `perf`, Intel VTune, Pyinstrument |\n",
    "| **Instrumenting profiler** | Modifies or wraps code to record *every function entry/exit* and measure exact times. | `cProfile`, `line_profiler`, TAU, mpiP (for MPI calls) |\n",
    "\n",
    "---\n",
    "\n",
    "## Sampling Profilers\n",
    "\n",
    "**How they work:**  \n",
    "A timer fires at regular intervals (e.g., every 1 ms). Each time:\n",
    "1. The profiler pauses the program briefly.\n",
    "2. Records the current function/line being executed.\n",
    "3. Resumes execution immediately.\n",
    "\n",
    "After many samples, the profiler estimates where most time is spent based on how often each line appears in the samples.\n",
    "\n",
    "**Example (Scalene):**\n",
    "| Line | Python % | Native % | GPU % |\n",
    "|------|-----------|----------|-------|\n",
    "| 12 | 45 | 10 | 0 |\n",
    "| 22 | 2 | 50 | 0 |\n",
    "| 35 | 0 | 0 | 50 |\n",
    "\n",
    "### Advantages\n",
    "- Very **low overhead** suitable for long HPC runs.  \n",
    "- Works with **JIT** or **native** code (Numba, C/C++, CUDA).  \n",
    "- Can attribute **CPU**, **native**, and **GPU** time separately.  \n",
    "- Doesn’t distort performance (no code rewriting).\n",
    "\n",
    "### Limitations\n",
    "- **Statistical**, not exact — tiny or rare functions may be missed.  \n",
    "- **Resolution** limited by sampling frequency.  \n",
    "- Results may vary slightly between runs.\n",
    "\n",
    "---\n",
    "\n",
    "## Instrumenting Profilers\n",
    "\n",
    "**How they work:**  \n",
    "Profiler inserts code around every function call to record precise start and end times.\n",
    "\n",
    "```python\n",
    "start = time.perf_counter()\n",
    "foo()\n",
    "elapsed = time.perf_counter() - start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe77204",
   "metadata": {},
   "source": [
    "## Pure Python vs. NumPy (native) hotspot demo\n",
    "\n",
    "We'll create two versions of the same computation:\n",
    "- A **pure Python** double loop (intentionally slow).\n",
    "- A **NumPy** vectorized version (native BLAS under the hood).\n",
    "\n",
    "We'll run Scalene **as a CLI** so it generates an HTML report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "241a087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting py_vs_numpy.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile py_vs_numpy.py\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "def slow_python(N):\n",
    "    X = np.arange(N**2).reshape(N,N)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            X[i,j] = X[i,j]**2\n",
    "    return X\n",
    "\n",
    "def fast_numpy(N):\n",
    "    X = np.arange(N**2).reshape(N,N)\n",
    "    X = X**2\n",
    "    return X\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    slow_python(2000)\n",
    "    fast_numpy(2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38bbf67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: The GPU is currently running in a mode that can reduce Scalene's accuracy when reporting GPU utilization.\n",
      "If you have sudo privileges, you can run this command (Linux only) to enable per-process GPU accounting:\n",
      "  python3 -m scalene.set_nvidia_gpu_modes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run scalene to create an HTML report (uncomment to execute).\n",
    "# The --html flag writes 'scalene_py_vs_numpy.html' next to the script.\n",
    "!scalene --html --outfile scalene_py_vs_numpy.html py_vs_numpy.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfb7fd0",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "\n",
    "| **Column** | **Meaning** | **How It’s Measured** | **Interpretation / What to Look For** |\n",
    "|-------------|-------------|------------------------|---------------------------------------|\n",
    "| **% of Time** | Total fraction of wall-clock runtime spent on this line (sum of Python + Native + GPU). | Statistical sampling of stack traces every few ms. | High → major hotspot. Focus optimization here. |\n",
    "| **% Python** | Time spent executing interpreted Python bytecode. | Samples taken while the GIL is held. | High → interpreter-bound → vectorize or JIT with Numba. |\n",
    "| **% Native** | Time spent in compiled/native code (NumPy, C/C++, Fortran, Numba CPU). | Separate sampling thread attributes time outside the GIL. | High → already optimized native code; algorithmic or I/O limits dominate. |\n",
    "| **% System** | Time in OS/kernel calls (I/O, sleep, etc.). | Samples where stack shows system-level frames. | High → I/O-bound or waiting on the OS. |\n",
    "| **% GPU** | Time the GPU was busy executing kernels launched by this line. | Hooks into CUDA runtime; counts active GPU time. | High → GPU compute-bound; check data transfers & kernel efficiency. |\n",
    "| **CPU Mem Avg (MB/s)** | Average rate of host-side allocations/frees while this line was active. | Hooks `malloc`/`free` and Python allocator; computes bytes / sec. | High → heavy allocation throughput. |\n",
    "| **CPU Mem Peak (MB)** | Maximum increase in total process memory after this line executed. | Tracks deltas in process RSS / heap size. | High → transient spikes or potential memory growth/leak. |\n",
    "| **GPU Mem Avg / Peak** | (Experimental) Device memory allocation rate / peak usage. | CUDA driver hooks — partial support (mainly CuPy). | Often blank for Numba CUDA — normal. |\n",
    "\n",
    "---\n",
    "\n",
    "###  Reading Tips\n",
    "- **High Python %** → optimize in Python space (Numba/vectorize).  \n",
    "- **High Native %** → library code is doing work; tune algorithms.  \n",
    "- **High GPU %** → GPU dominates; focus on data movement.  \n",
    "- **High CPU Mem Avg/Peak** → frequent or large host allocations.  \n",
    "- **High System %** → I/O or synchronization bottleneck.  \n",
    "- Blank GPU/Memory columns → no allocations or unsupported (normal for Numba CUDA).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1076aa23",
   "metadata": {},
   "source": [
    "\n",
    "## Numba (CPU JIT) demo\n",
    "\n",
    "Numba JIT-compiles Python to native code, which Scalene will attribute as **native time**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b05e411c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting numba_cpu.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile numba_cpu.py\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def matmul_numba(a, b):\n",
    "    return a @ b\n",
    "\n",
    "def main(n):\n",
    "    \n",
    "    # Warmup\n",
    "    a = np.random.rand(10,10)\n",
    "    b = np.random.rand(10,10)\n",
    "    c = matmul_numba\n",
    "    \n",
    "    # Test\n",
    "    a = np.random.rand(n, n)\n",
    "    b = np.random.rand(n, n)\n",
    "    c = matmul_numba(a, b)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7fa1b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: The GPU is currently running in a mode that can reduce Scalene's accuracy when reporting GPU utilization.\n",
      "If you have sudo privileges, you can run this command (Linux only) to enable per-process GPU accounting:\n",
      "  python3 -m scalene.set_nvidia_gpu_modes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!scalene --html --outfile scalene_numba_cpu.html numba_cpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5675356",
   "metadata": {},
   "source": [
    "\n",
    "## GPU with Numba CUDA\n",
    "\n",
    "A custom kernel to illustrate kernel launch vs. device compute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3058d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting numba_cuda.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile numba_cuda.py\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def f(a, x, y, out):\n",
    "    i = cuda.grid(1)\n",
    "    if i < x.size:\n",
    "        out[i] = a * x[i] + y[i]\n",
    "\n",
    "def main(n):\n",
    "    x = np.random.rand(n).astype(np.float32)\n",
    "    y = np.random.rand(n).astype(np.float32)\n",
    "    out = np.empty_like(x)\n",
    "\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_y = cuda.to_device(y)\n",
    "    d_out = cuda.device_array_like(x)\n",
    "\n",
    "    threads = 256\n",
    "    blocks = (n + threads - 1) // threads\n",
    "    f[blocks, threads](2.0, d_x, d_y, d_out)\n",
    "    cuda.synchronize()\n",
    "    print(\"sum:\", float(d_out.copy_to_host().sum()))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(50000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f4858a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum: 75009888.0\n",
      "NOTE: The GPU is currently running in a mode that can reduce Scalene's accuracy when reporting GPU utilization.\n",
      "If you have sudo privileges, you can run this command (Linux only) to enable per-process GPU accounting:\n",
      "  python3 -m scalene.set_nvidia_gpu_modes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!scalene --html --outfile scalene_numba_cuda.html numba_cuda.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1ce707",
   "metadata": {},
   "source": [
    "\n",
    "## Profiling `mpi4py` programs (rank-by-rank)\n",
    "\n",
    "Scalene does not aggregate across ranks automatically when using mpi4py. Hence, The common pattern is to **produce one report per rank**.\n",
    "\n",
    "One approach to deal with this is to use your MPI launcher to start each rank under Scalene and write a per-rank report. Examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5837190d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mpi_demo.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile mpi_demo.py\n",
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Example MPI program for profiling with Scalene\n",
    "This demonstrates typical MPI operations that you'd want to profile\n",
    "\"\"\"\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def expensive_computation(size):\n",
    "    \"\"\"Simulate some CPU-intensive work\"\"\"\n",
    "    data = np.random.rand(size, size)\n",
    "    result = np.linalg.inv(data @ data.T + np.eye(size))\n",
    "    return result\n",
    "\n",
    "def memory_intensive_operation(size):\n",
    "    \"\"\"Simulate memory allocation\"\"\"\n",
    "    arrays = []\n",
    "    for i in range(10):\n",
    "        arrays.append(np.random.rand(size, size))\n",
    "    return np.sum([arr.sum() for arr in arrays])\n",
    "\n",
    "def main():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "    \n",
    "    print(f\"Rank {rank}/{size} starting...\")\n",
    "    \n",
    "    # Different work for different ranks\n",
    "    if rank == 0:\n",
    "        # Root does some preparation\n",
    "        data = expensive_computation(1000)\n",
    "        total = memory_intensive_operation(500)\n",
    "        print(f\"Rank 0: Prepared data, total = {total:.2f}\")\n",
    "    else:\n",
    "        # Workers do their own computation\n",
    "        result = expensive_computation(100)\n",
    "        local_sum = memory_intensive_operation(1000)\n",
    "        print(f\"Rank {rank}: Computed result, sum = {local_sum:.2f}\")\n",
    "    \n",
    "    # Synchronize\n",
    "    comm.Barrier()\n",
    "    \n",
    "    # Gather operation\n",
    "    local_value = rank * 10.0\n",
    "    all_values = comm.gather(local_value, root=0)\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"Gathered values: {all_values}\")\n",
    "    \n",
    "    # Broadcast operation\n",
    "    if rank == 0:\n",
    "        broadcast_data = np.random.rand(1000, 1000)\n",
    "    else:\n",
    "        broadcast_data = None\n",
    "    \n",
    "    broadcast_data = comm.bcast(broadcast_data, root=0)\n",
    "    \n",
    "    # Everyone does some work with broadcast data\n",
    "    local_result = np.sum(broadcast_data) * rank\n",
    "    \n",
    "    # Reduce operation\n",
    "    total_result = comm.reduce(local_result, op=MPI.SUM, root=0)\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"Total result from reduce: {total_result:.2f}\")\n",
    "    \n",
    "    print(f\"Rank {rank} completed successfully\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df529f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 3/4 starting...\n",
      "Rank 2/4 starting...\n",
      "Rank 1/4 starting...\n",
      "Rank 0/4 starting...\n",
      "Rank 3: Computed result, sum = 5000400.23\n",
      "Rank 2: Computed result, sum = 5000206.24\n",
      "Rank 1: Computed result, sum = 4999641.77\n",
      "Rank 0: Prepared data, total = 1250162.33\n",
      "Gathered values: [0.0, 10.0, 20.0, 30.0]\n",
      "Rank 2 completed successfully\n",
      "Rank 3 completed successfully\n",
      "Rank 1 completed successfully\n",
      "Total result from reduce: 3001602.16\n",
      "Rank 0 completed successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To profile each rank programmatically:\n",
    "!mpiexec --allow-run-as-root -n 4 bash -c 'scalene --html --outfile profile-rank-${OMPI_COMM_WORLD_RANK}.html mpi_demo.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc076115",
   "metadata": {},
   "source": [
    "While `Scalene` can be used to profile individual MPI ranks, it's probably better to use manual timing `MPI.Wtime()` or an MPI specific profiler like `mpip`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
